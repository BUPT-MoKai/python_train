{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.0400\n",
      "step 100, training accuracy 0.8400\n",
      "step 200, training accuracy 0.9400\n",
      "step 300, training accuracy 0.8600\n",
      "step 400, training accuracy 0.9600\n",
      "step 500, training accuracy 0.9200\n",
      "step 600, training accuracy 0.9600\n",
      "step 700, training accuracy 0.9800\n",
      "step 800, training accuracy 0.9000\n",
      "step 900, training accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "#虚拟机带不动 -- \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#制造一些随机的噪声来打破完全对称\n",
    "def weight_variable(shape): \n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# tf.nn.conv2d是TensorFlow中的二维卷积函数\n",
    "#W是卷积参数（前两个数字代表卷积核的尺寸，第三个数字表示有多少个通道，最后一个数字表示卷积核的数量）\n",
    "#strides代表卷积模板移动的步长，第0位和第3为一定为1，中间两位表示横竖两个方向的步长\n",
    "#SAME代表给边界加上padding（在边界自动补0）让卷积的输出和输入保持同样（SAME）尺寸\n",
    "def conv2d(x, W): \n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') \n",
    "                                                                    \n",
    "#tf.nn.max_pool是TensorFlow中的最大池化函数\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784]) #特征\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) #真实label\n",
    "x_image = tf.reshape(x, [-1,28,28,1]) #前面的-1（Python里表示tensor的最后一个量，所以值对大值，有多少取多少）\n",
    "                                      #代表样本数量不固定，最后1代表颜色通道数量\n",
    "\n",
    "#第一个卷积层    \n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) #代表卷积核尺寸为5x5,1个颜色通道，32个不同的卷积核\n",
    "b_conv1 = bias_variable([32]) \n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) #卷积操作后加上偏置，接着再使用ReLU激活函数进行非线性处理\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#第二个卷积层\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#注意数值的计算\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024]) #tensor尺寸\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) #转换为一维向量\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "#减轻过拟合\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#将Dropdout层的输出连接到一个Softmax层，得到概率输出\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "#定义损失函数，优化器学习速率设为较小的1e-4\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "#准确率\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#开始训练过程，初始化所有参数\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_:batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_:batch[1], keep_prob:0.5})\n",
    "\n",
    "#得到整体的分类准确率   \n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict = {x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
